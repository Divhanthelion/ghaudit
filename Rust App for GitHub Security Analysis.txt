Architectural Design and Strategic Implementation of a High-Performance Rust Security Analysis Engine: A Comprehensive Research Report
1. Introduction: The Imperative of Automated Security Analysis in the Modern Supply Chain
The software development landscape has undergone a radical transformation in the last decade, shifting from monolithic, self-contained applications to distributed systems heavily reliant on open-source components. This shift has precipitated a corresponding evolution in the threat landscape. Adversaries no longer solely target the production environment; they increasingly target the software supply chain itself—the complex web of repositories, dependencies, build pipelines, and contributors that constitute modern software. The "shifting left" of security—integrating security analysis earlier into the development lifecycle—has moved from a best practice to an operational necessity.
This research report delineates the design and implementation of a next-generation security analysis application written in Rust. The choice of Rust is deliberate and strategic. As a systems programming language that guarantees memory safety without a garbage collector, Rust offers the performance profile of C++ with the safety guarantees required for security-critical tooling. A security scanner must process gigabytes of untrusted code; implementing such a tool in a memory-unsafe language introduces the ironic and dangerous possibility of the scanner itself becoming an attack vector via buffer overflows or use-after-free vulnerabilities triggered by malformed source files.
The proposed application is designed to analyze GitHub repositories for known security vulnerabilities through a multi-layered approach. It combines deterministic Static Application Security Testing (SAST) leveraging concrete syntax trees, Software Composition Analysis (SCA) utilizing distributed vulnerability databases, and cutting-edge probabilistic analysis powered by Large Language Models (LLMs). Furthermore, this report explores the integration of cryptographic provenance verification using the Supply-chain Levels for Software Artifacts (SLSA) framework and Sigstore, positioning the tool at the forefront of secure software supply chain methodologies.
2. System Architecture and Concurrency Models
The architectural foundation of a high-throughput security scanner must address two distinct classes of computational problems: I/O latency and CPU intensity. Interacting with the GitHub API, cloning repositories, and querying vulnerability databases are I/O-bound operations, where the system spends significant time waiting for network responses. Conversely, parsing source code, traversing syntax trees, and executing semantic queries are CPU-bound tasks that require maximizing processor utilization. A naive single-threaded approach would result in unacceptable performance, while an improper concurrency model could lead to resource exhaustion or deadlocks.
2.1 The Hybrid Concurrency Strategy: Synergizing Tokio and Rayon
To resolve the tension between I/O and CPU workloads, the proposed architecture employs a hybrid concurrency model that leverages two of Rust’s most mature ecosystems: tokio for asynchronous control and rayon for data parallelism.
The tokio runtime serves as the application's asynchronous control plane. It utilizes a work-stealing scheduler optimized for non-blocking I/O operations. In the context of this scanner, tokio manages the lifecycle of network requests to GitHub, handles rate limiting logic, and orchestrates the high-level workflow of the application. When the application awaits a response from the GitHub API via the octocrab client, the tokio runtime yields the thread to other tasks, ensuring that network latency does not stall the application.1 This is crucial for maintaining high throughput during the discovery phase, where the scanner may need to crawl metadata for thousands of repositories simultaneously.
However, utilizing tokio for heavy computation—such as parsing a massive Rust or C++ codebase—is an architectural anti-pattern. If a CPU-intensive task runs on a tokio worker thread, it prevents that thread from polling other I/O resources, effectively starving the async runtime. This phenomenon, often referred to as blocking the event loop, degrades the performance of the entire system.
To mitigate this, the architecture delegates CPU-bound analysis to a dedicated thread pool managed by rayon. rayon is designed specifically for parallel computation, utilizing a work-stealing strategy where idle threads actively take tasks from the queues of busy threads.3 This ensures that all available CPU cores are saturated with analysis work. The integration point between these two worlds is critical: the tokio-based crawler fetches data and passes file handles or content buffers through bounded channels (such as tokio::sync::mpsc) to the rayon pool. This "pipeline" pattern decouples ingestion from analysis, allowing each subsystem to scale independently based on the available system resources.5
2.2 State Management and the Actor Model
Managing shared state in a highly concurrent environment introduces significant complexity, particularly regarding data consistency and race conditions. For a security scanner, shared state might include a registry of scanned commit hashes (to avoid redundant processing), a cache of vulnerability definitions, or an aggregator for analysis results. Traditional mutex-based synchronization can lead to lock contention, where threads spend more time waiting for locks than performing work.
The Actor Model offers a robust alternative. In this paradigm, "actors" are independent units of computation that maintain their own private state and communicate exclusively via asynchronous messages. This eliminates the need for locks, as only one message is processed by an actor at a time. The Rust ecosystem provides frameworks like actix which implement this model.7
For this application, a "Registry Actor" can be designed to manage the deduplication of scan targets. When the crawler discovers a repository, it sends a message to the Registry Actor containing the repository ID and commit hash. The actor checks its internal state and responds with a directive to proceed or skip. This serialization of state access ensures data integrity without the performance penalties of fine-grained locking. Furthermore, the Actor Model simplifies error handling; if an analysis actor crashes due to a panic (e.g., encountering a deeply recursive file structure), a supervisor actor can restart it without destabilizing the entire application.8
2.3 High-Performance File System Traversal
Once repositories are cloned to the local file system, the scanner must identify relevant source files for analysis while ignoring build artifacts, binary files, and vendor directories that could skew results or waste resources. The standard library’s recursive directory iterator is insufficient for high-performance scenarios due to the synchronous nature of file system calls.
The jwalk crate provides a parallel directory traversal implementation that runs significantly faster than standard iterators on multi-core systems. However, speed must be balanced with intelligence. Security scanners must respect .gitignore and .ignore files to prevent false positives derived from analyzing temporary files or dependencies that are not part of the source distribution. The ignore crate, utilized by the high-performance search tool ripgrep, implements this logic efficiently. By integrating ignore into the traversal pipeline, the scanner ensures that it processes only the files that developers intend to commit, thereby aligning the analysis scope with the actual codebase.9
3. Data Acquisition: Interfacing with the GitHub Ecosystem
The efficacy of the analysis engine is contingent upon its ability to efficiently acquire target code and metadata. This involves robust interactions with the GitHub API and precise handling of Git protocols.
3.1 Semantic API Interaction with Octocrab
Interacting with GitHub's REST or GraphQL APIs via raw HTTP requests is error-prone and brittle. The octocrab crate provides a strongly typed, idiomatic Rust interface to GitHub, abstracting the complexities of serialization and authentication. This library is distinguished by its extensive coverage of the GitHub API surface, including Actions, Pull Requests, and Security Advisories.1
In the proposed application, octocrab serves multiple roles. First, it facilitates Target Discovery. The application can query for repositories based on criteria such as language (e.g., language:rust), popularity (stars), or recent activity. This allows the scanner to dynamically generate work queues based on real-time ecosystem data. Second, it handles Metadata Extraction. Before cloning, the scanner retrieves the latest commit SHA, default branch name, and existing security alerts. This metadata enriches the final report, providing context such as whether a detected vulnerability exists in a stale branch or active development line.
Critically, octocrab supports modern authentication mechanisms, including GitHub Apps authentication. This is essential for enterprise deployments where the scanner operates as an installed application with specific permissions, rather than relying on personal access tokens which carry higher security risks. The crate’s design utilizes the builder pattern for constructing complex API queries, ensuring that optional parameters are handled safely and expressively.11
3.2 Git Operations: The Choice Between Bindings and Pure Rust
Acquiring the source code involves cloning repositories, a non-trivial task that requires handling the Git protocol. There are two primary approaches in the Rust ecosystem: utilizing git2, which creates bindings to the C-based libgit2, or gitoxide, a pure Rust implementation.
While git2 is currently more feature-complete and battle-tested, relying on C bindings introduces a dependency on the system's linker and potential memory safety issues inherent to C. Conversely, gitoxide aligns with the project's goal of memory safety but may lack support for some advanced Git features.12 For this application, a hybrid approach or a strategic choice of git2 is recommended for the immediate term to ensure compatibility with all Git transfer protocols (SSH, HTTPS) and edge cases in repository packing. However, the architecture should abstract Git operations behind a trait (e.g., RepositorySource), allowing a seamless migration to gitoxide as it matures. This encapsulation ensures that the core analysis logic remains agnostic to the mechanism of code retrieval.
Alternatively, for environments where binary size and compilation time are paramount, the application could shell out to the system git binary using std::process::Command. While this reduces compilation complexity, it introduces a runtime dependency on the environment, which reduces the portability of the scanner.12 Therefore, the library-based approach (git2 or gitoxide) is preferred for a robust, self-contained security tool.
4. Static Application Security Testing (SAST): The Tree-Sitter Revolution
The core of the scanner's detection capability lies in Static Application Security Testing (SAST). Traditional SAST tools often rely on regular expressions or rigid AST parsers that fail when code is syntactically invalid (e.g., during active editing). The proposed application leverages tree-sitter, a parser generator tool and incremental parsing library, to overcome these limitations.
4.1 Concrete Syntax Trees and Robust Parsing
tree-sitter generates a Concrete Syntax Tree (CST) rather than an Abstract Syntax Tree (AST). The distinction is vital: an AST abstracts away "insignificant" details like whitespace, comments, and parentheses, whereas a CST preserves the code exactly as written. In security analysis, these "insignificant" details are often crucial. For example, a comment might contain a linter suppression directive (e.g., // undefined-variable: ignore) or a developer's note indicating known technical debt (e.g., // TODO: Fix this security hole). A CST-based parser allows the scanner to analyze these annotations alongside the code logic.13
Furthermore, tree-sitter is designed for fault tolerance. It can produce a usable syntax tree even in the presence of syntax errors, ensuring that the scanner can analyze code that may not currently compile. This is particularly valuable in CI/CD pipelines where a commit might break the build but still introduce a vulnerability that needs detection. tree-sitter parsers are available for a vast array of languages, allowing this Rust application to serve as a polyglot scanner, analyzing Rust, Python, JavaScript, and Go repositories with a unified architecture.13
4.2 The Query Engine: Pattern Matching with S-Expressions
The most powerful feature of tree-sitter for security researchers is its query language, which uses S-expressions (Lisp-like syntax) to match patterns within the syntax tree. This allows vulnerabilities to be defined as declarative data patterns rather than imperative code, decoupling the detection logic from the scanner's core engine.
4.2.1 Detecting Unsafe Rust Patterns
In the Rust ecosystem, the unsafe keyword is a primary indicator of potential memory safety violations. While unsafe is sometimes necessary for FFI or low-level optimizations, its presence requires heightened scrutiny. A tree-sitter query can effortlessly identify all unsafe blocks:


Scheme




(unsafe_block) @unsafe_usage

To identify functions that are inherently unsafe, shifting the burden of safety to the caller, the query would target function definitions with the unsafe modifier:


Scheme




(function_item 
 (function_modifiers) @mods 
 (#match? @mods "unsafe")) @unsafe_fn

The application can parse these captures to report the exact file, line number, and context of the unsafe usage. Furthermore, using the CST's preservation of comments, the scanner can cross-reference these hits with // SAFETY: comments (a standard convention in Rust) to determine if the developer has documented the safety invariants. Missing safety documentation for an unsafe block could be flagged as a policy violation.16
4.2.2 Hardcoded Secrets and Entropy Analysis
Hardcoded credentials remain a pervasive vulnerability. Simple string matching often yields high false positives (e.g., flagging the word "password" in a UI label). tree-sitter improves precision by restricting the search to specific syntactic contexts, such as variable assignments or constant definitions.


Scheme




(let_declaration
 pattern: (identifier) @var_name
 value: (string_literal) @value
 (#match? @var_name "(?i)(api_key|secret|token|password)")
)

This query identifies let bindings where the variable name suggests a secret. The scanner can then perform secondary analysis on the captured @value node. This secondary analysis might involve checking the string's entropy (randomness) to distinguish between a placeholder string like "change_me" (low entropy) and a real AWS key (high entropy). By combining syntactic context with entropy analysis, the scanner significantly reduces false positives compared to naive regex scanning.14
4.2.3 Injection Vulnerabilities and Data Flow
For languages like Python or SQL, injection attacks are a critical concern. tree-sitter queries can detect dangerous patterns, such as string concatenation used to construct SQL queries.


Scheme




(call_expression
 function: (identifier) @func_name
 arguments: (argument_list
   (binary_expression
     left: (string_literal)
     operator: "+"
     right: (identifier)
   )
 )
 (#match? @func_name "^(execute|query)$")
)

This query targets function calls named execute or query where an argument involves adding a string literal to a variable. This structural pattern matching is far more robust than regex, as it is unaffected by line breaks or spacing variations.21
4.3 Semantic Analysis with HIR and Rust-Analyzer
While tree-sitter excels at syntactic analysis, it lacks semantic understanding—it does not know that variable x on line 10 is the same as variable x on line 50, nor does it understand type inference. To achieve deep analysis, the application integrates libraries from the rust-analyzer project, specifically ra_ap_hir (High-Level Intermediate Representation).
HIR provides an object-oriented-like view of the code, resolving names, types, and modules. By converting the tree-sitter findings into HIR structures, the scanner can perform Reachability Analysis. For instance, if an unsafe block contains a potential buffer overflow, reachability analysis determines if that block can be triggered by external user input via a public API. This moves the tool from a simple "linter" to a sophisticated vulnerability detector capable of analyzing control flow and data flow across module boundaries.23
5. Software Composition Analysis (SCA): Securing the Supply Chain
Modern applications are assembled, not just written. A significant portion of the codebase consists of third-party dependencies managed by Cargo. The SCA module is responsible for auditing these dependencies for known vulnerabilities.
5.1 The OSV Schema and Ecosystem Integration
The scanner integrates with the Open Source Vulnerability (OSV) database. Unlike legacy databases like the NVD which are often slow to update and API-limited, OSV is a distributed, community-driven database that aggregates vulnerabilities from multiple ecosystems (RustSec, PyPA, GitHub Advisories, etc.) into a unified, machine-readable JSON format.25
The scanner utilizes the osv crate to query this database. The OSV schema is designed for precision; it allows vulnerabilities to be specified by package version ranges or even specific Git commit hashes. This granularity is essential for reducing false positives. For example, a vulnerability might exist in v1.2.0 but be fixed in v1.2.1. The scanner parses the Cargo.lock file—which contains the exact resolved versions of all dependencies—and queries OSV to determine if any locked version is vulnerable. This is superior to checking Cargo.toml, which only specifies version constraints (e.g., ^1.2), not the actual artifact used in the build.27
5.2 Cryptographic Provenance and SLSA Verification
The "cutting edge" of supply chain security moves beyond accidental vulnerabilities to malicious tampering. Attackers increasingly compromise package maintainer accounts to inject malware into legitimate packages. To defend against this, the scanner implements verification of Supply-chain Levels for Software Artifacts (SLSA) provenance.
Using the sigstore-verification crate, the application verifies the cryptographic signatures associated with dependencies. It checks for:
1. Provenance Existence: Does the package have a signed statement describing how it was built?
2. Builder Authenticity: Was the package built by a trusted, tamper-resistant build service (e.g., a specific GitHub Actions workflow verified by OIDC)?
3. Source Integrity: Does the provenance link the binary artifact back to the specific source repository and commit hash expected?
This verification creates a chain of trust from the source code to the final binary, mitigating the risk of using compromised artifacts.30
5.3 Binary Auditing with Cargo-Auditable
To support post-build analysis, the application integrates with cargo-auditable. This tool embeds the dependency tree (the Cargo.lock data) directly into the compiled binary in a dedicated section. This allows the scanner to analyze compiled executables for vulnerable dependencies without needing the original source code or lockfiles. This capability is crucial for analyzing legacy binaries or closed-source artifacts within an organization, ensuring that even "black box" components are subject to security scrutiny.33
6. The Frontier: AI-Driven Vulnerability Detection
Traditional SAST and SCA tools are deterministic; they find what they are programmed to find. To detect novel or logic-based vulnerabilities, the research incorporates Generative AI and Large Language Models (LLMs).
6.1 Privacy-First Architecture with Local Inference
A significant barrier to adopting AI in security is data privacy. Organizations are hesitant to send proprietary code to external APIs like OpenAI. To address this, the proposed architecture utilizes candle, a minimalist machine learning framework for Rust developed by Hugging Face. candle allows the scanner to run quantized LLMs (such as Mistral-7B or StarCoder) locally on the user's hardware (CPU or GPU) without data leaving the environment.35
By running inference locally, the scanner can perform AI-driven analysis in air-gapped environments or high-security enclaves. The architecture treats the local LLM as a sophisticated heuristic engine. When the deterministic SAST engine flags a "suspicious" but inconclusive pattern (e.g., complex pointer arithmetic), it passes the code snippet to the candle-backed model for a probabilistic assessment.36
6.2 Context Engineering and RAG for Code
LLMs have limited context windows (the amount of text they can process at once). Simply pasting an entire file into a prompt often leads to "lost in the middle" phenomena where the model ignores critical details. To optimize performance, the scanner employs Context Engineering and Retrieval Augmented Generation (RAG) specialized for code.
Instead of raw text, the scanner generates a textual representation of the Call Graph or Control Flow Graph (CFG). It uses tree-sitter to extract the relevant function, its callers, and the callees, effectively "trimming" the code to the relevant execution path. This condensed representation is high-density information that fits efficiently into the LLM's context window.38
For larger repositories, the scanner generates vector embeddings of code chunks using a model like BERT or CodeBERT (via candle). These embeddings are stored in a local vector index (using crates like lance). When analyzing a specific function, the system retrieves semantically related code snippets—such as variable definitions or utility functions located in different files—and injects them into the prompt. This "Just-In-Time" context loading allows the LLM to reason about cross-file dependencies without loading the entire repository.40
6.3 Mitigating Hallucinations with Chain-of-Thought
A primary risk with LLMs is hallucination—confidently reporting vulnerabilities that do not exist. To mitigate this, the scanner employs Chain-of-Thought (CoT) prompting techniques. The system constructs prompts that force the model to explicitly reason through the code execution steps before delivering a verdict.
For example, the prompt might structure the task as:
1. Analyze: "Trace the flow of the variable user_input."
2. Reason: "Does user_input reach the unsafe block without validation?"
3. Conclude: "Verdict: VULNERABLE / SAFE."
By forcing the model to output its reasoning trace, the system not only improves accuracy but also provides an auditable explanation for the security analyst, transforming the "black box" of AI into an interpretable tool.42
7. Reporting and Standardization
The final stage of the pipeline is reporting. To ensure the scanner's findings can be consumed by other tools (IDEs, dashboards, issue trackers), the application standardizes its output using the Static Analysis Results Interchange Format (SARIF).
7.1 SARIF Serialization
SARIF is the industry-standard JSON format for static analysis tools. The serde_sarif crate is used to construct strongly typed SARIF objects. This includes mapping internal vulnerability types to SARIF "rules," and converting file paths and line numbers into SARIF "physical locations."
The architecture utilizes the builder pattern (e.g., ResultBuilder, RunBuilder) provided by serde_sarif to programmatically construct these complex JSON structures. This ensures that the output is always schema-compliant. By outputting SARIF, the scanner's results can be natively uploaded to GitHub Code Scanning, displayed in VS Code via the SARIF Viewer extension, or ingested by enterprise vulnerability management platforms.44
7.2 Efficient Data Handling with Serde
Throughout the application, the serde framework acts as the data translation layer. Whether parsing Cargo.toml (TOML), reading OSV responses (JSON), or generating SARIF reports, serde provides high-performance serialization and deserialization. The design leverages serde's derive macros to keep the codebase clean and declarative, while custom serializers handle edge cases like normalizing version strings or handling polymorphic fields in the OSV schema.44
8. Implementation Roadmap
To realize this design, the development should follow a phased approach:
1. Phase 1: Foundation (Ingestion & SAST): Implement the tokio/octocrab crawler and the tree-sitter analysis engine. Focus on high-confidence syntactic patterns (unsafe blocks, secrets).
2. Phase 2: Supply Chain (SCA): Integrate osv and cargo-lock parsing. Implement basic dependency vulnerability reporting.
3. Phase 3: Deep Security (Provenance & AI): Add sigstore-verification for SLSA checks and integrate candle for local LLM verification of complex findings.
4. Phase 4: Optimization & Reporting: Tune rayon thread pools, implement caching, and finalize SARIF output for CI/CD integration.
9. Conclusion
The proposed Rust-based security application represents a synthesis of modern high-performance computing and advanced cybersecurity practices. By marrying the raw speed and safety of Rust with the structural precision of tree-sitter, the distributed intelligence of the OSV ecosystem, and the reasoning capabilities of local LLMs, this architecture addresses the critical needs of the current threat landscape. It moves beyond simple "grep-like" scanning to offer deep, semantic, and context-aware analysis.
As software supply chains become increasingly complex and targeted, the integration of cryptographic verification (SLSA/Sigstore) and AI-driven logic analysis positions this tool not merely as a bug finder, but as a comprehensive platform for ensuring the integrity and security of the software lifecycle. This design creates a scalable, future-proof foundation capable of evolving alongside the sophisticated adversaries it is designed to thwart.
________________
Data Tables
Table 1: Runtime Selection and Responsibilities
Component
	Runtime
	Justification
	Key Crates
	Ingestion
	Tokio (Async)
	Handles high-latency network I/O (GitHub API) without blocking threads.
	octocrab, reqwest, tokio
	Analysis
	Rayon (Parallel)
	Maximizes CPU utilization for parsing and query execution via work-stealing.
	tree-sitter, rayon
	State
	Actix/Actor
	Manages shared mutable state (deduplication) without lock contention.
	actix, tokio::sync
	Table 2: Detection Capabilities by Layer
Layer
	Technology
	Detection Scope
	Example Finding
	Syntactic
	tree-sitter
	Code patterns, Keywords, Structure
	unsafe {... } block usage.
	Semantic
	rust-analyzer (HIR)
	Data flow, Type resolution, Reachability
	User input reaching unsafe block.
	Supply Chain
	osv, cargo-lock
	Known Vulnerabilities (CVEs)
	Dependency log4j v2.14.0 found.
	Provenance
	sigstore
	Build Integrity, Tampering
	Invalid signature on axum crate.
	Cognitive
	Local LLM (candle)
	Logic bugs, Intent analysis
	TOCTOU race condition in file access.
	Works cited
1. octocrab - crates.io: Rust Package Registry, accessed December 27, 2025, https://crates.io/crates/octocrab
2. reqwest vs hyper: Rust HTTP Client Comparison 2024 - Generalist Programmer, accessed December 27, 2025, https://generalistprogrammer.com/comparisons/reqwest-vs-hyper
3. Can you explain that Tokio vs crossbeam vs rayon a bit more? Should I default to... | Hacker News, accessed December 27, 2025, https://news.ycombinator.com/item?id=28510257
4. Rayon or Tokio for heavy filesystem I/O workloads? : r/rust - Reddit, accessed December 27, 2025, https://www.reddit.com/r/rust/comments/xec77k/rayon_or_tokio_for_heavy_filesystem_io_workloads/
5. Rust Concurrency: When to Use (and Avoid) Async Runtimes | by Leapcell - Medium, accessed December 27, 2025, https://leapcell.medium.com/rust-concurrency-when-to-use-and-avoid-async-runtimes-43556cff6b62
6. Number of Tokio threads vs number of Rayon threads in IO and CPU intensive app??? : r/rust - Reddit, accessed December 27, 2025, https://www.reddit.com/r/rust/comments/1btggxp/number_of_tokio_threads_vs_number_of_rayon/
7. actix/actix: Actor framework for Rust. - GitHub, accessed December 27, 2025, https://github.com/actix/actix
8. Efficient indexing with Quickwit Rust actor framework, accessed December 27, 2025, https://quickwit.io/blog/quickwit-actor-framework
9. Directory Traversal - Rust Cookbook, accessed December 27, 2025, https://rust-lang-nursery.github.io/rust-cookbook/file/dir.html
10. Blazing-Fast Directory Tree Traversal: Haskell Streamly Beats Rust - Reddit, accessed December 27, 2025, https://www.reddit.com/r/rust/comments/1iekv4t/blazingfast_directory_tree_traversal_haskell/
11. Rust external web APIs: The definitive guide - LogRocket Blog, accessed December 27, 2025, https://blog.logrocket.com/rust-external-web-apis-the-definitive-guide/
12. Use `git2-rs` or `gitoxide` instead of `git` command! · Issue #39 · thinkgos/goup-rs - GitHub, accessed December 27, 2025, https://github.com/thinkgos/goup-rs/issues/39
13. Tree-sitter: Introduction, accessed December 27, 2025, https://tree-sitter.github.io/
14. Lightweight linting with tree-sitter - DeepSource, accessed December 27, 2025, https://deepsource.com/blog/lightweight-linting
15. tree_sitter - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/tree-sitter
16. How to get or view the count of unsafe block in a project or library in crates.io - help, accessed December 27, 2025, https://users.rust-lang.org/t/how-to-get-or-view-the-count-of-unsafe-block-in-a-project-or-library-in-crates-io/66824
17. Finding the "root" unsafe parts in a Rust code base - Reddit, accessed December 27, 2025, https://www.reddit.com/r/rust/comments/u7ojnm/finding_the_root_unsafe_parts_in_a_rust_code_base/
18. Query in tree_sitter - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/tree-sitter/latest/tree_sitter/struct.Query.html
19. Learn How to Navigate Code Structures and Extract Details Using Tree-sitter - Medium, accessed December 27, 2025, https://medium.com/@rijulrajtkeey2/learn-how-to-navigate-code-structures-and-extract-details-using-tree-sitter-510d6d2801f1
20. Unraveling Tree-Sitter Queries: Your Guide to Code Analysis Magic - DEV Community, accessed December 27, 2025, https://dev.to/shrsv/unraveling-tree-sitter-queries-your-guide-to-code-analysis-magic-41il
21. SQL injection inside python f-strings #6073 - GitHub, accessed December 27, 2025, https://github.com/nvim-treesitter/nvim-treesitter/discussions/6073
22. My tree-sitter injection queries to mimic Pycharm's language injection comments - Reddit, accessed December 27, 2025, https://www.reddit.com/r/HelixEditor/comments/1mmi8g3/my_treesitter_injection_queries_to_mimic_pycharms/
23. ra_ap_hir - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/ra_ap_hir/latest/ra_ap_hir/
24. Help building a code browser - The Rust Programming Language Forum, accessed December 27, 2025, https://users.rust-lang.org/t/help-building-a-code-browser/102791
25. API | OSV - Google, accessed December 27, 2025, https://google.github.io/osv.dev/api/
26. OSV - Open Source Vulnerabilities, accessed December 27, 2025, https://osv.dev/
27. osv - Rust Package Registry - Crates.io, accessed December 27, 2025, https://crates.io/crates/osv
28. osv - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/osv
29. Open Source Vulnerability format - GitHub Pages, accessed December 27, 2025, https://ossf.github.io/osv-schema/
30. Home · Sigstore, accessed December 27, 2025, https://www.sigstore.dev/
31. sigstore-verification - crates.io: Rust Package Registry, accessed December 27, 2025, https://crates.io/crates/sigstore-verification/0.1.1
32. sigstore-verification - crates.io: Rust Package Registry, accessed December 27, 2025, https://crates.io/crates/sigstore-verification
33. cargo-auditable(1) - Arch manual pages, accessed December 27, 2025, https://man.archlinux.org/man/cargo-auditable.1.en
34. rust-secure-code/cargo-auditable: Make production Rust binaries auditable - GitHub, accessed December 27, 2025, https://github.com/rust-secure-code/cargo-auditable
35. huggingface/candle: Minimalist ML framework for Rust - GitHub, accessed December 27, 2025, https://github.com/huggingface/candle
36. ML Library Comparison: Burn vs Candle : r/rust - Reddit, accessed December 27, 2025, https://www.reddit.com/r/rust/comments/1op3ad1/ml_library_comparison_burn_vs_candle/
37. How to load and run local LLMs (e.g., Llama) in Rust? - help, accessed December 27, 2025, https://users.rust-lang.org/t/how-to-load-and-run-local-llms-e-g-llama-in-rust/134864
38. Effective context engineering for AI agents - Anthropic, accessed December 27, 2025, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents
39. Issue Localization via LLM-Driven Iterative Code Graph Searching - arXiv, accessed December 27, 2025, https://arxiv.org/html/2503.22424v2
40. What Is Retrieval-Augmented Generation (RAG)? An Overview - Palo Alto Networks, accessed December 27, 2025, https://www.paloaltonetworks.com/cyberpedia/what-is-retrieval-augmented-generation
41. Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG - arXiv, accessed December 27, 2025, https://arxiv.org/abs/2406.11147
42. Prompt Engineering Techniques | IBM, accessed December 27, 2025, https://www.ibm.com/think/topics/prompt-engineering-techniques
43. Advanced Prompt Engineering Techniques for 2025: Beyond Basic Instructions - Reddit, accessed December 27, 2025, https://www.reddit.com/r/PromptEngineering/comments/1k7jrt7/advanced_prompt_engineering_techniques_for_2025/
44. serde_sarif - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/serde-sarif
45. sarif_rust - Rust - Docs.rs, accessed December 27, 2025, https://docs.rs/sarif_rust
46. Examples - Serde, accessed December 27, 2025, https://serde.rs/examples.html